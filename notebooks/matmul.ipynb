{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e10f6446a312a2",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from lizard import lizard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "487a6c80e8414314",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T22:25:19.166648Z",
     "start_time": "2025-10-26T22:25:19.160747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lizard(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d383e7f2514d15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T13:43:35.921308Z",
     "start_time": "2025-10-27T13:43:34.696818Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'triton'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfla\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfla\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     ABCAttention,\n\u001b[1;32m      5\u001b[0m     Attention,\n\u001b[1;32m      6\u001b[0m     BasedLinearAttention,\n\u001b[1;32m      7\u001b[0m     BitAttention,\n\u001b[1;32m      8\u001b[0m     Comba,\n\u001b[1;32m      9\u001b[0m     DeltaFormerAttention,\n\u001b[1;32m     10\u001b[0m     DeltaNet,\n\u001b[1;32m     11\u001b[0m     GatedDeltaNet,\n\u001b[1;32m     12\u001b[0m     GatedDeltaProduct,\n\u001b[1;32m     13\u001b[0m     GatedLinearAttention,\n\u001b[1;32m     14\u001b[0m     GatedSlotAttention,\n\u001b[1;32m     15\u001b[0m     HGRN2Attention,\n\u001b[1;32m     16\u001b[0m     HGRNAttention,\n\u001b[1;32m     17\u001b[0m     LightNetAttention,\n\u001b[1;32m     18\u001b[0m     LinearAttention,\n\u001b[1;32m     19\u001b[0m     LogLinearMamba2,\n\u001b[1;32m     20\u001b[0m     MesaNet,\n\u001b[1;32m     21\u001b[0m     MomAttention,\n\u001b[1;32m     22\u001b[0m     MultiheadLatentAttention,\n\u001b[1;32m     23\u001b[0m     MultiScaleRetention,\n\u001b[1;32m     24\u001b[0m     NativeSparseAttention,\n\u001b[1;32m     25\u001b[0m     PaTHAttention,\n\u001b[1;32m     26\u001b[0m     ReBasedLinearAttention,\n\u001b[1;32m     27\u001b[0m     RodimusAttention,\n\u001b[1;32m     28\u001b[0m     RWKV6Attention,\n\u001b[1;32m     29\u001b[0m     RWKV7Attention\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfla\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     ABCForCausalLM,\n\u001b[1;32m     33\u001b[0m     ABCModel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     TransformerModel\n\u001b[1;32m     80\u001b[0m )\n\u001b[1;32m     82\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mABCAttention\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mABCForCausalLM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mABCModel\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttention\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransformerForCausalLM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransformerModel\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRWKV7Attention\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRWKV7ForCausalLM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRWKV7Model\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    109\u001b[0m ]\n",
      "File \u001b[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/layers/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2023-2025, Songlin Yang, Yu Zhang\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ABCAttention\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Attention\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbased\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BasedLinearAttention\n",
      "File \u001b[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/layers/abc.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01meinops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rearrange\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfla\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FusedRMSNormGated, RMSNorm, RotaryEmbedding, ShortConvolution\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfla\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m swiglu, swish\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfla\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chunk_abc\n",
      "File \u001b[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/modules/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfla\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvolution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImplicitLongConvolution, LongConvolution, ShortConvolution\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfla\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfused_bitlinear\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BitLinear, FusedBitLinear\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfla\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfused_cross_entropy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FusedCrossEntropyLoss\n",
      "File \u001b[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/modules/convolution.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtriton\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtriton\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtl\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01meinops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rearrange\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'triton'"
     ]
    }
   ],
   "source": [
    "from fla import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff0f1ab8d69d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e96adb705dbcc0b",
   "metadata": {},
   "source": [
    "### Matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2767c9820ce17aea",
   "metadata": {},
   "source": [
    "##### numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7165c824501e7759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:07.968499Z",
     "start_time": "2025-11-02T12:37:07.886240Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import overload\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1705db99da21d1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:10.047296Z",
     "start_time": "2025-11-02T12:37:10.044859Z"
    }
   },
   "outputs": [],
   "source": [
    "@overload\n",
    "def matmul(a: npt.NDArray[np.float32], b: npt.NDArray[np.float32]) -> np.ndarray: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42355acce79fc533",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7a83a1a664dc67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:12.112868Z",
     "start_time": "2025-11-02T12:37:12.109825Z"
    }
   },
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    return a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bcfe727f8f1ad9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:13.607356Z",
     "start_time": "2025-11-02T12:37:13.598013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul(np.ones([1, 4], dtype='f'), np.ones([4, 1], dtype='f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d645ed26d416969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:15.997956Z",
     "start_time": "2025-11-02T12:37:15.993216Z"
    }
   },
   "outputs": [],
   "source": [
    "A = np.array([[1.0, 2.0], [3.0, 4.0]], dtype='f')\n",
    "B = np.array([[5.0, 6.0], [7.0, 8.0]], dtype='f')\n",
    "C = np.array([[19.0, 22.0], [43.0, 50.0]])\n",
    "assert np.allclose(matmul(A, B), C), \"failed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "274a38864dffcf7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:18.627666Z",
     "start_time": "2025-11-02T12:37:18.623927Z"
    }
   },
   "outputs": [],
   "source": [
    "A = np.array([1.0, 2.0, 3.0], dtype='f')\n",
    "B = np.array([[4.0], [5.0], [6.0]], dtype='f')\n",
    "C = np.array([[32.0]])\n",
    "assert np.allclose(matmul(A, B), C), \"failed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16bf72f7f0abbc33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:20.530594Z",
     "start_time": "2025-11-02T12:37:20.140973Z"
    }
   },
   "outputs": [],
   "source": [
    "A = np.random.rand(8192, 6144)\n",
    "B = np.random.rand(6144, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2ea3f08d2707b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:26.703538Z",
     "start_time": "2025-11-02T12:37:23.113889Z"
    }
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "result = timeit.timeit('matmul(A, B)', globals=globals(), number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4ab65b99dea2e25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:29.352831Z",
     "start_time": "2025-11-02T12:37:29.345462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5828007500094827"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92227d1bbb028c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:51.887818Z",
     "start_time": "2025-11-02T12:37:31.603499Z"
    }
   },
   "outputs": [],
   "source": [
    "result = timeit.timeit('matmul(A, B)', globals=globals(), number=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a8174337e0fa219",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:54.311502Z",
     "start_time": "2025-11-02T12:37:54.306114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.280263916996773"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78e654c9ba8fa5ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:38:00.316110Z",
     "start_time": "2025-11-02T12:37:57.602318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  2 13:38:00 2025    profiler\n",
      "\n",
      "         4 function calls in 2.664 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    2.661    2.661    2.661    2.661 1409129159.py:1(matmul)\n",
      "        1    0.003    0.003    2.664    2.664 <string>:1(<module>)\n",
      "        1    0.000    0.000    2.664    2.664 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x1047e2950>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile, pstats\n",
    "\n",
    "cProfile.run('matmul(A, B)', 'profiler')\n",
    "pstats.Stats('profiler').strip_dirs().sort_stats('tottime').print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f5548938e43e940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:38:04.876421Z",
     "start_time": "2025-11-02T12:38:04.869983Z"
    }
   },
   "outputs": [],
   "source": [
    "def profile(matmul, a, b):\n",
    "    import cProfile, pstats\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    matmul(a, b)\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "    stats.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6806b9b009fe3240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:38:09.758040Z",
     "start_time": "2025-11-02T12:38:07.349111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2 function calls in 2.394 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    2.394    2.394    2.394    2.394 /var/folders/_z/49hgcx6x4db7pjpfzjcphlcm0000gn/T/ipykernel_92810/1409129159.py:1(matmul)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile(matmul, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7f0ccba4f13cebd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:38:16.231668Z",
     "start_time": "2025-11-02T12:38:15.247271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snakeviz in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tornado>=2.0 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from snakeviz) (6.5.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install snakeviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da687fe92bdee205",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:38:44.257157Z",
     "start_time": "2025-11-02T12:38:38.225708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file '/var/folders/_z/49hgcx6x4db7pjpfzjcphlcm0000gn/T/tmppui8t1p_'.\n",
      "Embedding SnakeViz in this document...\n",
      "<function display at 0x106a037f0>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe id='snakeviz-b9dd8b28-b7ec-11f0-81d1-6a0a9745c2cf' frameborder=0 seamless width='100%' height='1000'></iframe>\n",
       "<script>document.getElementById(\"snakeviz-b9dd8b28-b7ec-11f0-81d1-6a0a9745c2cf\").setAttribute(\"src\", \"http://\" + document.location.hostname + \":8080/snakeviz/%2Fvar%2Ffolders%2F_z%2F49hgcx6x4db7pjpfzjcphlcm0000gn%2FT%2Ftmppui8t1p_\")</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext snakeviz\n",
    "%snakeviz matmul(A, B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3eb9f9b503baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da64be9d22691d70",
   "metadata": {},
   "source": [
    "#### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e69bfc4cdd101622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:45:13.672416Z",
     "start_time": "2025-11-02T12:45:12.518356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "577ba19c0b17064",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:45:35.452219Z",
     "start_time": "2025-11-02T12:45:35.421838Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "366fade7a787dff9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:45:36.240071Z",
     "start_time": "2025-11-02T12:45:36.234164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d571d852f4f62ba9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:46:35.398807Z",
     "start_time": "2025-11-02T12:46:35.379310Z"
    }
   },
   "outputs": [],
   "source": [
    "@overload\n",
    "def matmul_pytorch(a: ..., b: ...): ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c9aa35f619f6458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:49:17.461557Z",
     "start_time": "2025-11-02T12:49:17.450960Z"
    }
   },
   "outputs": [],
   "source": [
    "def matmul_pytorch(a, b):\n",
    "    import torch\n",
    "    return torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de4dea8e0eeca7cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:55:15.953413Z",
     "start_time": "2025-11-02T12:55:15.928930Z"
    }
   },
   "outputs": [],
   "source": [
    "A = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "B = torch.tensor([[5.0, 6.0], [7.0, 8.0]])\n",
    "C = torch.tensor([[19.0, 22.0], [43.0, 50.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0809b6561f3e656",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:56:57.456302Z",
     "start_time": "2025-11-02T12:56:57.437931Z"
    }
   },
   "outputs": [],
   "source": [
    "assert torch.allclose(matmul_pytorch(A, B), C), \"failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df3d6f6dd3482eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor(np.random.rand(8192, 6144), device=\"cpu\")\n",
    "B = torch.tensor(np.random.rand(6144, 4096), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74d56760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  2 14:09:22 2025    profiler\n",
      "\n",
      "         5 function calls in 1.899 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    1.895    1.895    1.895    1.895 {built-in method torch.matmul}\n",
      "        1    0.003    0.003    1.899    1.899 <string>:1(<module>)\n",
      "        1    0.000    0.000    1.899    1.899 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    1.895    1.895 2296730478.py:1(matmul_pytorch)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x11d4f1120>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile, pstats\n",
    "\n",
    "cProfile.run('matmul_pytorch(A, B)', 'profiler')\n",
    "pstats.Stats('profiler').strip_dirs().sort_stats('tottime').print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dc3ed55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The snakeviz extension is already loaded. To reload it, use:\n",
      "  %reload_ext snakeviz\n",
      " \n",
      "*** Profile stats marshalled to file '/var/folders/_z/49hgcx6x4db7pjpfzjcphlcm0000gn/T/tmpw7hql467'.\n",
      "Embedding SnakeViz in this document...\n",
      "<function display at 0x106a037f0>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe id='snakeviz-339b763c-b7ed-11f0-81d1-6a0a9745c2cf' frameborder=0 seamless width='100%' height='1000'></iframe>\n",
       "<script>document.getElementById(\"snakeviz-339b763c-b7ed-11f0-81d1-6a0a9745c2cf\").setAttribute(\"src\", \"http://\" + document.location.hostname + \":8080/snakeviz/%2Fvar%2Ffolders%2F_z%2F49hgcx6x4db7pjpfzjcphlcm0000gn%2FT%2Ftmpw7hql467\")</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext snakeviz\n",
    "%snakeviz matmul_pytorch(A, B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761ae3fb",
   "metadata": {},
   "source": [
    "NVIDIA T4 GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346daa14",
   "metadata": {},
   "source": [
    "- Turing Architecture\n",
    "- No HBM - only uses GDDR6\n",
    "- 2560 Tensor Core\n",
    "-c\n",
    "---\n",
    "\n",
    "- L0 - warp-level cache\n",
    "- L1 cache + shared memory (64-128 KB per SM)\n",
    "- L2 cache (4 MB global)\n",
    "- GDDRM6 VRAM (16 GB, 320 GB/s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba32eb0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09fb6dcc",
   "metadata": {},
   "source": [
    "#### Triton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fc0fca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jku-ai-practical-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
