{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "from lizard import lizard",
   "id": "96e10f6446a312a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T22:25:19.166648Z",
     "start_time": "2025-10-26T22:25:19.160747Z"
    }
   },
   "cell_type": "code",
   "source": "lizard(3)",
   "id": "487a6c80e8414314",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T13:43:35.921308Z",
     "start_time": "2025-10-27T13:43:34.696818Z"
    }
   },
   "cell_type": "code",
   "source": "from fla import *",
   "id": "b2d383e7f2514d15",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'triton'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/__init__.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# -*- coding: utf-8 -*-\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      4\u001B[0m     ABCAttention,\n\u001B[1;32m      5\u001B[0m     Attention,\n\u001B[1;32m      6\u001B[0m     BasedLinearAttention,\n\u001B[1;32m      7\u001B[0m     BitAttention,\n\u001B[1;32m      8\u001B[0m     Comba,\n\u001B[1;32m      9\u001B[0m     DeltaFormerAttention,\n\u001B[1;32m     10\u001B[0m     DeltaNet,\n\u001B[1;32m     11\u001B[0m     GatedDeltaNet,\n\u001B[1;32m     12\u001B[0m     GatedDeltaProduct,\n\u001B[1;32m     13\u001B[0m     GatedLinearAttention,\n\u001B[1;32m     14\u001B[0m     GatedSlotAttention,\n\u001B[1;32m     15\u001B[0m     HGRN2Attention,\n\u001B[1;32m     16\u001B[0m     HGRNAttention,\n\u001B[1;32m     17\u001B[0m     LightNetAttention,\n\u001B[1;32m     18\u001B[0m     LinearAttention,\n\u001B[1;32m     19\u001B[0m     LogLinearMamba2,\n\u001B[1;32m     20\u001B[0m     MesaNet,\n\u001B[1;32m     21\u001B[0m     MomAttention,\n\u001B[1;32m     22\u001B[0m     MultiheadLatentAttention,\n\u001B[1;32m     23\u001B[0m     MultiScaleRetention,\n\u001B[1;32m     24\u001B[0m     NativeSparseAttention,\n\u001B[1;32m     25\u001B[0m     PaTHAttention,\n\u001B[1;32m     26\u001B[0m     ReBasedLinearAttention,\n\u001B[1;32m     27\u001B[0m     RodimusAttention,\n\u001B[1;32m     28\u001B[0m     RWKV6Attention,\n\u001B[1;32m     29\u001B[0m     RWKV7Attention\n\u001B[1;32m     30\u001B[0m )\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     32\u001B[0m     ABCForCausalLM,\n\u001B[1;32m     33\u001B[0m     ABCModel,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     79\u001B[0m     TransformerModel\n\u001B[1;32m     80\u001B[0m )\n\u001B[1;32m     82\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mABCAttention\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mABCForCausalLM\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mABCModel\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAttention\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTransformerForCausalLM\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTransformerModel\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    108\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRWKV7Attention\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRWKV7ForCausalLM\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRWKV7Model\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    109\u001B[0m ]\n",
      "File \u001B[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/layers/__init__.py:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# -*- coding: utf-8 -*-\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Copyright (c) 2023-2025, Songlin Yang, Yu Zhang\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mabc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ABCAttention\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mattn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Attention\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbased\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BasedLinearAttention\n",
      "File \u001B[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/layers/abc.py:13\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01meinops\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m rearrange\n\u001B[0;32m---> 13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodules\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FusedRMSNormGated, RMSNorm, RotaryEmbedding, ShortConvolution\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodules\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m swiglu, swish\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mabc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchunk\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m chunk_abc\n",
      "File \u001B[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/modules/__init__.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# -*- coding: utf-8 -*-\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodules\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconvolution\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ImplicitLongConvolution, LongConvolution, ShortConvolution\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodules\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfused_bitlinear\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BitLinear, FusedBitLinear\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodules\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfused_cross_entropy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FusedCrossEntropyLoss\n",
      "File \u001B[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/modules/convolution.py:11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mF\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtriton\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtriton\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlanguage\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtl\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01meinops\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m rearrange\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'triton'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "eaff0f1ab8d69d1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Matmul",
   "id": "6e96adb705dbcc0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### numpy",
   "id": "2767c9820ce17aea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:07.968499Z",
     "start_time": "2025-11-02T12:37:07.886240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import overload\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt"
   ],
   "id": "7165c824501e7759",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:10.047296Z",
     "start_time": "2025-11-02T12:37:10.044859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@overload\n",
    "def matmul(a: npt.NDArray[np.float32], b: npt.NDArray[np.float32]) -> np.ndarray: ..."
   ],
   "id": "c1705db99da21d1e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "42355acce79fc533"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:12.112868Z",
     "start_time": "2025-11-02T12:37:12.109825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def matmul(a, b):\n",
    "    return a @ b"
   ],
   "id": "6b7a83a1a664dc67",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:13.607356Z",
     "start_time": "2025-11-02T12:37:13.598013Z"
    }
   },
   "cell_type": "code",
   "source": "matmul(np.ones([1, 4], dtype='f'), np.ones([4, 1], dtype='f'))",
   "id": "2bcfe727f8f1ad9b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:15.997956Z",
     "start_time": "2025-11-02T12:37:15.993216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = np.array([[1.0, 2.0], [3.0, 4.0]], dtype='f')\n",
    "B = np.array([[5.0, 6.0], [7.0, 8.0]], dtype='f')\n",
    "C = np.array([[19.0, 22.0], [43.0, 50.0]])\n",
    "assert np.allclose(matmul(A, B), C), \"failed.\""
   ],
   "id": "5d645ed26d416969",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:18.627666Z",
     "start_time": "2025-11-02T12:37:18.623927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = np.array([1.0, 2.0, 3.0], dtype='f')\n",
    "B = np.array([[4.0], [5.0], [6.0]], dtype='f')\n",
    "C = np.array([[32.0]])\n",
    "assert np.allclose(matmul(A, B), C), \"failed.\""
   ],
   "id": "274a38864dffcf7e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:20.530594Z",
     "start_time": "2025-11-02T12:37:20.140973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = np.random.rand(8192, 6144)\n",
    "B = np.random.rand(6144, 4096)"
   ],
   "id": "16bf72f7f0abbc33",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:26.703538Z",
     "start_time": "2025-11-02T12:37:23.113889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import timeit\n",
    "result = timeit.timeit('matmul(A, B)', globals=globals(), number=1)"
   ],
   "id": "c2ea3f08d2707b91",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:29.352831Z",
     "start_time": "2025-11-02T12:37:29.345462Z"
    }
   },
   "cell_type": "code",
   "source": "result",
   "id": "c4ab65b99dea2e25",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5828007500094827"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:51.887818Z",
     "start_time": "2025-11-02T12:37:31.603499Z"
    }
   },
   "cell_type": "code",
   "source": "result = timeit.timeit('matmul(A, B)', globals=globals(), number=10)\n",
   "id": "92227d1bbb028c5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:37:54.311502Z",
     "start_time": "2025-11-02T12:37:54.306114Z"
    }
   },
   "cell_type": "code",
   "source": "result",
   "id": "7a8174337e0fa219",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.280263916996773"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:38:00.316110Z",
     "start_time": "2025-11-02T12:37:57.602318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cProfile, pstats\n",
    "\n",
    "cProfile.run('matmul(A, B)', 'profiler')\n",
    "pstats.Stats('profiler').strip_dirs().sort_stats('tottime').print_stats()"
   ],
   "id": "78e654c9ba8fa5ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  2 13:38:00 2025    profiler\n",
      "\n",
      "         4 function calls in 2.664 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    2.661    2.661    2.661    2.661 1409129159.py:1(matmul)\n",
      "        1    0.003    0.003    2.664    2.664 <string>:1(<module>)\n",
      "        1    0.000    0.000    2.664    2.664 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x1047e2950>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:38:04.876421Z",
     "start_time": "2025-11-02T12:38:04.869983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def profile(matmul, a, b):\n",
    "    import cProfile, pstats\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    matmul(a, b)\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "    stats.print_stats()"
   ],
   "id": "2f5548938e43e940",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:38:09.758040Z",
     "start_time": "2025-11-02T12:38:07.349111Z"
    }
   },
   "cell_type": "code",
   "source": "profile(matmul, A, B)",
   "id": "6806b9b009fe3240",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2 function calls in 2.394 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    2.394    2.394    2.394    2.394 /var/folders/_z/49hgcx6x4db7pjpfzjcphlcm0000gn/T/ipykernel_92810/1409129159.py:1(matmul)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:38:16.231668Z",
     "start_time": "2025-11-02T12:38:15.247271Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install snakeviz\n",
   "id": "b7f0ccba4f13cebd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snakeviz in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: tornado>=2.0 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from snakeviz) (6.5.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:38:44.257157Z",
     "start_time": "2025-11-02T12:38:38.225708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext snakeviz\n",
    "%snakeviz matmul(A, B)\n"
   ],
   "id": "da687fe92bdee205",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The snakeviz extension is already loaded. To reload it, use:\n",
      "  %reload_ext snakeviz\n",
      " \n",
      "*** Profile stats marshalled to file '/var/folders/_z/49hgcx6x4db7pjpfzjcphlcm0000gn/T/tmpkss8nft2'.\n",
      "Embedding SnakeViz in this document...\n",
      "<function display at 0x10270f880>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "<iframe id='snakeviz-dcbf4720-b7e8-11f0-b814-6a0a9745c2cf' frameborder=0 seamless width='100%' height='1000'></iframe>\n",
       "<script>document.getElementById(\"snakeviz-dcbf4720-b7e8-11f0-b814-6a0a9745c2cf\").setAttribute(\"src\", \"http://\" + document.location.hostname + \":8080/snakeviz/%2Fvar%2Ffolders%2F_z%2F49hgcx6x4db7pjpfzjcphlcm0000gn%2FT%2Ftmpkss8nft2\")</script>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "89a3eb9f9b503baa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PyTorch",
   "id": "da64be9d22691d70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:45:13.672416Z",
     "start_time": "2025-11-02T12:45:12.518356Z"
    }
   },
   "cell_type": "code",
   "source": "! pip install torch",
   "id": "e69bfc4cdd101622",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (2.9.0)\r\n",
      "Requirement already satisfied: filelock in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from torch) (3.20.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from torch) (4.15.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from torch) (2025.9.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:45:35.452219Z",
     "start_time": "2025-11-02T12:45:35.421838Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "577ba19c0b17064",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:45:36.240071Z",
     "start_time": "2025-11-02T12:45:36.234164Z"
    }
   },
   "cell_type": "code",
   "source": "torch.__version__",
   "id": "366fade7a787dff9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:46:35.398807Z",
     "start_time": "2025-11-02T12:46:35.379310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@overload\n",
    "def matmul_pytorch(a: ..., b: ...): ..."
   ],
   "id": "d571d852f4f62ba9",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:49:17.461557Z",
     "start_time": "2025-11-02T12:49:17.450960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def matmul_pytorch(a, b):\n",
    "    import torch\n",
    "    return torch.matmul(a, b)"
   ],
   "id": "8c9aa35f619f6458",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:55:15.953413Z",
     "start_time": "2025-11-02T12:55:15.928930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "B = torch.tensor([[5.0, 6.0], [7.0, 8.0]])\n",
    "C = torch.tensor([[19.0, 22.0], [43.0, 50.0]])"
   ],
   "id": "de4dea8e0eeca7cc",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:56:57.456302Z",
     "start_time": "2025-11-02T12:56:57.437931Z"
    }
   },
   "cell_type": "code",
   "source": "assert torch.allclose(matmul_pytorch(A, B), C), \"failed\"",
   "id": "c0809b6561f3e656",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "df3d6f6dd3482eb6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
