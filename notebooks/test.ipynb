{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "from lizard import lizard",
   "id": "96e10f6446a312a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T22:25:19.166648Z",
     "start_time": "2025-10-26T22:25:19.160747Z"
    }
   },
   "cell_type": "code",
   "source": "lizard(3)",
   "id": "487a6c80e8414314",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T13:43:35.921308Z",
     "start_time": "2025-10-27T13:43:34.696818Z"
    }
   },
   "cell_type": "code",
   "source": "from fla import *",
   "id": "b2d383e7f2514d15",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'triton'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/__init__.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# -*- coding: utf-8 -*-\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      4\u001B[0m     ABCAttention,\n\u001B[1;32m      5\u001B[0m     Attention,\n\u001B[1;32m      6\u001B[0m     BasedLinearAttention,\n\u001B[1;32m      7\u001B[0m     BitAttention,\n\u001B[1;32m      8\u001B[0m     Comba,\n\u001B[1;32m      9\u001B[0m     DeltaFormerAttention,\n\u001B[1;32m     10\u001B[0m     DeltaNet,\n\u001B[1;32m     11\u001B[0m     GatedDeltaNet,\n\u001B[1;32m     12\u001B[0m     GatedDeltaProduct,\n\u001B[1;32m     13\u001B[0m     GatedLinearAttention,\n\u001B[1;32m     14\u001B[0m     GatedSlotAttention,\n\u001B[1;32m     15\u001B[0m     HGRN2Attention,\n\u001B[1;32m     16\u001B[0m     HGRNAttention,\n\u001B[1;32m     17\u001B[0m     LightNetAttention,\n\u001B[1;32m     18\u001B[0m     LinearAttention,\n\u001B[1;32m     19\u001B[0m     LogLinearMamba2,\n\u001B[1;32m     20\u001B[0m     MesaNet,\n\u001B[1;32m     21\u001B[0m     MomAttention,\n\u001B[1;32m     22\u001B[0m     MultiheadLatentAttention,\n\u001B[1;32m     23\u001B[0m     MultiScaleRetention,\n\u001B[1;32m     24\u001B[0m     NativeSparseAttention,\n\u001B[1;32m     25\u001B[0m     PaTHAttention,\n\u001B[1;32m     26\u001B[0m     ReBasedLinearAttention,\n\u001B[1;32m     27\u001B[0m     RodimusAttention,\n\u001B[1;32m     28\u001B[0m     RWKV6Attention,\n\u001B[1;32m     29\u001B[0m     RWKV7Attention\n\u001B[1;32m     30\u001B[0m )\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     32\u001B[0m     ABCForCausalLM,\n\u001B[1;32m     33\u001B[0m     ABCModel,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     79\u001B[0m     TransformerModel\n\u001B[1;32m     80\u001B[0m )\n\u001B[1;32m     82\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mABCAttention\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mABCForCausalLM\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mABCModel\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAttention\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTransformerForCausalLM\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTransformerModel\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    108\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRWKV7Attention\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRWKV7ForCausalLM\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRWKV7Model\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    109\u001B[0m ]\n",
      "File \u001B[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/layers/__init__.py:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# -*- coding: utf-8 -*-\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Copyright (c) 2023-2025, Songlin Yang, Yu Zhang\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mabc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ABCAttention\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mattn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Attention\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbased\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BasedLinearAttention\n",
      "File \u001B[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/layers/abc.py:13\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01meinops\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m rearrange\n\u001B[0;32m---> 13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodules\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FusedRMSNormGated, RMSNorm, RotaryEmbedding, ShortConvolution\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodules\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m swiglu, swish\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mabc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchunk\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m chunk_abc\n",
      "File \u001B[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/modules/__init__.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# -*- coding: utf-8 -*-\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodules\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconvolution\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ImplicitLongConvolution, LongConvolution, ShortConvolution\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodules\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfused_bitlinear\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BitLinear, FusedBitLinear\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodules\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfused_cross_entropy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FusedCrossEntropyLoss\n",
      "File \u001B[0;32m~/PycharmProjects/jku-ai-practical-project/flash-linear-attention/fla/modules/convolution.py:11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mF\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtriton\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtriton\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlanguage\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtl\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01meinops\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m rearrange\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'triton'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "eaff0f1ab8d69d1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Matmul",
   "id": "6e96adb705dbcc0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### numpy",
   "id": "2767c9820ce17aea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T11:54:54.239383Z",
     "start_time": "2025-11-02T11:54:54.230170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import overload\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt"
   ],
   "id": "7165c824501e7759",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T11:58:08.162640Z",
     "start_time": "2025-11-02T11:58:08.135707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@overload\n",
    "def matmul(a: npt.NDArray[np.float32], b: npt.NDArray[np.float32]) -> np.ndarray: ..."
   ],
   "id": "c1705db99da21d1e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "42355acce79fc533"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T11:58:09.223787Z",
     "start_time": "2025-11-02T11:58:09.220919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def matmul(a, b):\n",
    "    return a @ b"
   ],
   "id": "6b7a83a1a664dc67",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:01:42.601615Z",
     "start_time": "2025-11-02T12:01:42.584139Z"
    }
   },
   "cell_type": "code",
   "source": "matmul(np.ones([1, 4], dtype='f'), np.ones([4, 1], dtype='f'))",
   "id": "2bcfe727f8f1ad9b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:07:13.317497Z",
     "start_time": "2025-11-02T12:07:13.309182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = np.array([[1.0, 2.0], [3.0, 4.0]], dtype='f')\n",
    "B = np.array([[5.0, 6.0], [7.0, 8.0]], dtype='f')\n",
    "C = np.array([[19.0, 22.0], [43.0, 50.0]])\n",
    "assert np.allclose(matmul(A, B), C), \"failed.\""
   ],
   "id": "5d645ed26d416969",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:09:30.099694Z",
     "start_time": "2025-11-02T12:09:30.071223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = np.array([1.0, 2.0, 3.0], dtype='f')\n",
    "B = np.array([[4.0], [5.0], [6.0]], dtype='f')\n",
    "C = np.array([[32.0]])\n",
    "assert np.allclose(matmul(A, B), C), \"failed.\""
   ],
   "id": "274a38864dffcf7e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:13:42.503040Z",
     "start_time": "2025-11-02T12:13:41.893968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = np.random.rand(8192, 6144)\n",
    "B = np.random.rand(6144, 4096)"
   ],
   "id": "16bf72f7f0abbc33",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:19:06.611755Z",
     "start_time": "2025-11-02T12:19:02.941066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import timeit\n",
    "result = timeit.timeit('matmul(A, B)', globals=globals(), number=1)"
   ],
   "id": "c2ea3f08d2707b91",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:19:43.628937Z",
     "start_time": "2025-11-02T12:19:43.610884Z"
    }
   },
   "cell_type": "code",
   "source": "result",
   "id": "c4ab65b99dea2e25",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6558565419982187"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:21:07.545971Z",
     "start_time": "2025-11-02T12:19:55.896744Z"
    }
   },
   "cell_type": "code",
   "source": "result = timeit.timeit('matmul(A, B)', globals=globals(), number=10)\n",
   "id": "92227d1bbb028c5",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:21:26.485Z",
     "start_time": "2025-11-02T12:21:26.473833Z"
    }
   },
   "cell_type": "code",
   "source": "result",
   "id": "7a8174337e0fa219",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.63746687499224"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:23:07.409506Z",
     "start_time": "2025-11-02T12:23:04.222338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cProfile, pstats\n",
    "\n",
    "cProfile.run('matmul(A, B)', 'profiler')\n",
    "pstats.Stats('profiler').strip_dirs().sort_stats('tottime').print_stats()"
   ],
   "id": "78e654c9ba8fa5ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  2 13:23:07 2025    profiler\n",
      "\n",
      "         4 function calls in 3.166 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    3.163    3.163    3.163    3.163 1409129159.py:1(matmul)\n",
      "        1    0.003    0.003    3.166    3.166 <string>:1(<module>)\n",
      "        1    0.000    0.000    3.166    3.166 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x1066a8c10>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:26:03.353767Z",
     "start_time": "2025-11-02T12:26:03.341851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def profile(matmul, a, b):\n",
    "    import cProfile, pstats\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    matmul(a, b)\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "    stats.print_stats()"
   ],
   "id": "2f5548938e43e940",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:26:06.965868Z",
     "start_time": "2025-11-02T12:26:03.927481Z"
    }
   },
   "cell_type": "code",
   "source": "profile(matmul, A, B)",
   "id": "6806b9b009fe3240",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2 function calls in 3.015 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    3.015    3.015    3.015    3.015 /var/folders/_z/49hgcx6x4db7pjpfzjcphlcm0000gn/T/ipykernel_91327/1409129159.py:1(matmul)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:26:38.810495Z",
     "start_time": "2025-11-02T12:26:37.007254Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install snakeviz\n",
   "id": "b7f0ccba4f13cebd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snakeviz\r\n",
      "  Downloading snakeviz-2.2.2-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Requirement already satisfied: tornado>=2.0 in /Users/mahdikhashan/miniconda3/envs/jku-ai-practical-project/lib/python3.10/site-packages (from snakeviz) (6.5.1)\r\n",
      "Downloading snakeviz-2.2.2-py3-none-any.whl (183 kB)\r\n",
      "Installing collected packages: snakeviz\r\n",
      "Successfully installed snakeviz-2.2.2\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T12:28:02.835727Z",
     "start_time": "2025-11-02T12:27:47.354730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext snakeviz\n",
    "%snakeviz matmul(A, B)\n"
   ],
   "id": "da687fe92bdee205",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file '/var/folders/_z/49hgcx6x4db7pjpfzjcphlcm0000gn/T/tmpsgz9jkai'.\n",
      "Embedding SnakeViz in this document...\n",
      "<function display at 0x104b3f880>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "<iframe id='snakeviz-5e6ecf86-b7e7-11f0-b6fd-6a0a9745c2cf' frameborder=0 seamless width='100%' height='1000'></iframe>\n",
       "<script>document.getElementById(\"snakeviz-5e6ecf86-b7e7-11f0-b6fd-6a0a9745c2cf\").setAttribute(\"src\", \"http://\" + document.location.hostname + \":8080/snakeviz/%2Fvar%2Ffolders%2F_z%2F49hgcx6x4db7pjpfzjcphlcm0000gn%2FT%2Ftmpsgz9jkai\")</script>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "89a3eb9f9b503baa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
